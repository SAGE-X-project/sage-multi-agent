
# ---------- Root & Client ----------
ROOT_AGENT_PORT=18080
CLIENT_PORT=8086

# ---------- Gateway (reverse proxy that may tamper) ----------
GATEWAY_PORT=5500

# ---------- Internal Payment Agent (HTTP debug server; 일부 스크립트에서 사용) ----------
PAYMENT_AGENT_PORT=19083
MEDICAL_AGENT_PORT=19082


# If SAGE is ON, key is required:
PAYMENT_JWK_FILE=./keys/payment.jwk
PAYMENT_KEM_JWK_FILE=./keys/kem/payment.x25519.jwk

MEDICAL_JWK_FILE=./keys/medical.jwk
MEDICAL_KEM_JWK_FILE=./keys/kem/medical.x25519.jwk

# (optional) Explicit DID; 없으면 secp256k1 JWK로부터 주소 기반 DID 유도
# PAYMENT_DID=did:sage:ethereum:0x1111111111111111111111111111111111111111

# ---------- Debug: sub-agent SAGE toggles (지금은 IN-PROC이므로 영향 거의 없음) ----------
PLANNING_SAGE_ENABLED=true
MEDICAL_SAGE_ENABLED=true
PAYMENT_SAGE_ENABLED=true


# ========================================
# LLM Provider Configuration
# ========================================
# Available providers: openai, gemini, gemini-native, anthropic, claude
# Default: openai
export LLM_PROVIDER=openai

# ---------- OpenAI Configuration ----------
export OPENAI_API_KEY={YOUR_OPENAI_API_KEY}
# Optional: Override base URL (e.g., for Azure OpenAI or local servers)
# export OPENAI_BASE_URL=https://api.openai.com/v1
# Optional: Override model (default: gpt-4o-mini)
# export OPENAI_MODEL=gpt-4o-mini

# ---------- Gemini Configuration ----------
# Option 1: Use Gemini's OpenAI-compatible endpoint (LLM_PROVIDER=gemini)
# Option 2: Use Gemini's native API (LLM_PROVIDER=gemini-native) - Recommended
# export LLM_PROVIDER=gemini-native
# export GEMINI_API_KEY={YOUR_GEMINI_API_KEY}
# Optional: Override model
# For gemini-native: gemini-2.0-flash-exp (default), gemini-2.0-pro, gemini-2.5-flash
# For gemini (OpenAI-compatible): gemini-2.5-flash (default)
# export GEMINI_MODEL=gemini-2.0-flash-exp

# ---------- Anthropic/Claude Configuration ----------
# export LLM_PROVIDER=anthropic
# export ANTHROPIC_API_KEY={YOUR_ANTHROPIC_API_KEY}
# Optional: Override model (default: claude-3-5-sonnet-20241022)
# Available models: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
# export ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ---------- Common LLM Settings ----------
# Timeout for LLM API calls (default: 12s)
# export LLM_TIMEOUT=12s
# Allow using LLM without API key for localhost servers
# export LLM_ALLOW_NO_KEY=true